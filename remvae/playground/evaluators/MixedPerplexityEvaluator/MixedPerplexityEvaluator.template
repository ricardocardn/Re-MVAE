def evaluate_perplexity(image_model, text_model, loader, tokenizer, device, results_dir):
    print("\nEvaluating Mixed Perplexity...")
    evaluator = MixedPerplexityEvaluator(
        image_model, text_model, loader, tokenizer, device=device
    )
    image_to_text_perp, text_to_image_perp = evaluator.evaluate()
    print(f"Image-to-text perplexity: {round(image_to_text_perp, 2)}")
    print(f"Text reconstruction perplexity: {round(text_to_image_perp, 2)}")
    save_metrics({
        "image_to_text_perplexity": image_to_text_perp,
        "text_to_image_perplexity": text_to_image_perp
    }, results_dir, "eval_mixed_perplexity.json")